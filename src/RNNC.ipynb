{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47e26673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"google/civil_comments\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef23be38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full train size: 1804874\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39da5a5f484b4b34a30512b6b0cc5ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/97320 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# configuration\n",
    "label_cols = [\n",
    "    \"toxicity\",\n",
    "    \"severe_toxicity\",\n",
    "    \"obscene\",\n",
    "    \"threat\",\n",
    "    \"insult\",\n",
    "    \"identity_attack\",\n",
    "    \"sexual_explicit\",\n",
    "]\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 2\n",
    "\n",
    "train_ds = ds[\"train\"]\n",
    "val_ds = ds[\"validation\"]\n",
    "test_ds = ds[\"test\"] if \"test\" in ds else None\n",
    "print(f\"Full train size: {len(train_ds)}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "def preprocess(batch):\n",
    "    enc = tokenizer(\n",
    "        batch[\"text\"], truncation=True, padding=\"max_length\", max_length=MAX_LEN\n",
    "    )\n",
    "    # binarize labels at 0.5\n",
    "    labels = []\n",
    "    for i in range(len(batch[\"text\"])):\n",
    "        labels.append([1 if float(batch[c][i]) >= 0.5 else 0 for c in label_cols])\n",
    "    enc[\"labels\"] = labels\n",
    "    return enc\n",
    "\n",
    "\n",
    "train_enc = train_ds.map(preprocess, batched=True, remove_columns=train_ds.column_names)\n",
    "val_enc = val_ds.map(preprocess, batched=True, remove_columns=val_ds.column_names)\n",
    "\n",
    "test_enc = None\n",
    "if test_ds is not None:\n",
    "    test_enc = test_ds.map(\n",
    "        preprocess, batched=True, remove_columns=test_ds.column_names\n",
    "    )\n",
    "\n",
    "train_enc.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_enc.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "if test_enc is not None:\n",
    "    test_enc.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "train_loader = DataLoader(train_enc, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_enc, batch_size=BATCH_SIZE * 2, shuffle=False)\n",
    "\n",
    "test_loader = (\n",
    "    DataLoader(test_enc, batch_size=BATCH_SIZE * 2, shuffle=False)\n",
    "    if test_enc is not None\n",
    "    else None\n",
    ")\n",
    "\n",
    "\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_labels, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        x = self.embedding(input_ids)\n",
    "        outputs, _ = self.lstm(x)  # [B, T, 2H]\n",
    "        lengths = attention_mask.sum(dim=1)\n",
    "        idx = (\n",
    "            (lengths - 1)\n",
    "            .clamp(min=0)\n",
    "            .unsqueeze(1)\n",
    "            .unsqueeze(2)\n",
    "            .expand(-1, 1, outputs.size(2))\n",
    "        )\n",
    "        last_hidden = outputs.gather(1, idx).squeeze(1)\n",
    "        logits = self.fc(self.dropout(last_hidden))\n",
    "        return logits\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "588c083f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1: 100%|██████████| 56403/56403 [10:54<00:00, 86.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | train_loss 0.0467 | val_loss 0.0403 | val_acc 0.9857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 2: 100%|██████████| 56403/56403 [10:46<00:00, 87.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 | train_loss 0.0413 | val_loss 0.0397 | val_acc 0.9858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mani/.pyenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mani/.pyenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "val_auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_acc",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "0857499e-d59f-4364-8c3c-c05e7e3175fd",
       "rows": [
        [
         "0",
         "toxicity",
         "0.95",
         "0.631",
         "0.951",
         "0.95",
         "0.639",
         "0.951"
        ],
        [
         "1",
         "severe_toxicity",
         null,
         "0.0",
         "1.0",
         null,
         "0.0",
         "1.0"
        ],
        [
         "2",
         "obscene",
         "0.973",
         "0.364",
         "0.996",
         "0.978",
         "0.421",
         "0.996"
        ],
        [
         "3",
         "threat",
         "0.955",
         "0.149",
         "0.998",
         "0.953",
         "0.123",
         "0.998"
        ],
        [
         "4",
         "insult",
         "0.961",
         "0.657",
         "0.965",
         "0.962",
         "0.667",
         "0.966"
        ],
        [
         "5",
         "identity_attack",
         "0.973",
         "0.097",
         "0.993",
         "0.971",
         "0.093",
         "0.993"
        ],
        [
         "6",
         "sexual_explicit",
         "0.967",
         "0.241",
         "0.998",
         "0.967",
         "0.237",
         "0.998"
        ],
        [
         "7",
         "AVG",
         "0.963",
         "0.305",
         "0.986",
         "0.964",
         "0.311",
         "0.986"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toxicity</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>severe_toxicity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>identity_attack</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sexual_explicit</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AVG</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label  val_auc  val_f1  val_acc  test_auc  test_f1  test_acc\n",
       "0         toxicity    0.950   0.631    0.951     0.950    0.639     0.951\n",
       "1  severe_toxicity      NaN   0.000    1.000       NaN    0.000     1.000\n",
       "2          obscene    0.973   0.364    0.996     0.978    0.421     0.996\n",
       "3           threat    0.955   0.149    0.998     0.953    0.123     0.998\n",
       "4           insult    0.961   0.657    0.965     0.962    0.667     0.966\n",
       "5  identity_attack    0.973   0.097    0.993     0.971    0.093     0.993\n",
       "6  sexual_explicit    0.967   0.241    0.998     0.967    0.237     0.998\n",
       "7              AVG    0.963   0.305    0.986     0.964    0.311     0.986"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "def safe_auc(y_true, y_score):\n",
    "    # y_true, y_score shape: [N, L]\n",
    "    au = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        yi = y_true[:, i]\n",
    "        ysi = y_score[:, i]\n",
    "        if len(np.unique(yi)) < 2:\n",
    "            tau.append(np.nan)\n",
    "        else:\n",
    "            try:\n",
    "                val = roc_auc_score(yi, ysi)\n",
    "                tau.append(val)\n",
    "            except Exception:\n",
    "                # in rare numerical cases\n",
    "                tau.append(np.nan)\n",
    "    return np.array(tau)\n",
    "\n",
    "\n",
    "model = RNNClassifier(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    embed_dim=128,\n",
    "    hidden_dim=128,\n",
    "    num_labels=len(label_cols),\n",
    "    pad_idx=tokenizer.pad_token_id,\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f\"Training epoch {epoch}\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].float().to(device)\n",
    "\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    steps = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].float().to(device)\n",
    "\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= 0.5).float()\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (preds == labels).float().mean().item()\n",
    "            steps += 1\n",
    "\n",
    "    print(\n",
    "        f\"epoch {epoch} | train_loss {total_loss/len(train_loader):.4f} | \"\n",
    "        f\"val_loss {val_loss/steps:.4f} | val_acc {val_acc/steps:.4f}\"\n",
    "    )\n",
    "\n",
    "# Collect full-val and full-test predictions for per-label metrics\n",
    "\n",
    "\n",
    "def collect_preds(dloader):\n",
    "    all_y = []\n",
    "    all_scores = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].float()\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            probs = torch.sigmoid(logits).cpu()\n",
    "            all_y.append(labels)\n",
    "            all_scores.append(probs)\n",
    "    return torch.cat(all_y, dim=0).numpy(), torch.cat(all_scores, dim=0).numpy()\n",
    "\n",
    "\n",
    "val_y, val_scores = collect_preds(val_loader)\n",
    "val_pred = (val_scores >= 0.5).astype(int)\n",
    "\n",
    "if test_loader is not None:\n",
    "    test_y, test_scores = collect_preds(test_loader)\n",
    "    test_pred = (test_scores >= 0.5).astype(int)\n",
    "else:\n",
    "    test_y = test_scores = test_pred = None\n",
    "\n",
    "# Compute per-label metrics\n",
    "rows = []\n",
    "for i, label in enumerate(label_cols):\n",
    "    vy = val_y[:, i]\n",
    "    vs = val_scores[:, i]\n",
    "    vp = val_pred[:, i]\n",
    "    v_auc = np.nan\n",
    "    if len(np.unique(vy)) > 1:\n",
    "        v_auc = roc_auc_score(vy, vs)\n",
    "    v_f1 = f1_score(vy, vp)\n",
    "    v_acc = accuracy_score(vy, vp)\n",
    "\n",
    "    row = {\"label\": label, \"val_auc\": v_auc, \"val_f1\": v_f1, \"val_acc\": v_acc}\n",
    "\n",
    "    if test_y is not None:\n",
    "        ty = test_y[:, i]\n",
    "        ts = test_scores[:, i]\n",
    "        tp = test_pred[:, i]\n",
    "        t_auc = np.nan\n",
    "        if len(np.unique(ty)) > 1:\n",
    "            t_auc = roc_auc_score(ty, ts)\n",
    "        t_f1 = f1_score(ty, tp)\n",
    "        t_acc = accuracy_score(ty, tp)\n",
    "        row.update({\"test_auc\": t_auc, \"test_f1\": t_f1, \"test_acc\": t_acc})\n",
    "    else:\n",
    "        row.update({\"test_auc\": np.nan, \"test_f1\": np.nan, \"test_acc\": np.nan})\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "metrics_df = pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\n",
    "        \"label\",\n",
    "        \"val_auc\",\n",
    "        \"val_f1\",\n",
    "        \"val_acc\",\n",
    "        \"test_auc\",\n",
    "        \"test_f1\",\n",
    "        \"test_acc\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "avg_vals = metrics_df.drop(columns=[\"label\"]).mean(numeric_only=True)\n",
    "avg_row = {**{\"label\": \"AVG\"}, **avg_vals.to_dict()}\n",
    "metrics_df = pd.concat([metrics_df, pd.DataFrame([avg_row])], ignore_index=True)\n",
    "\n",
    "metrics_df = metrics_df.round(3)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e865f7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark (CPU) on test set:\n",
      " - samples: 97320\n",
      " - total_inference_seconds_all_labels: 57.510928\n",
      " - throughput_samples_per_sec_all_labels: 1692.20\n",
      " - avg_per_sample_latency_ms_all_labels: 0.590947\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "test_infer_seconds",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "per_sample_ms",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "39f8d407-d521-44f1-beda-d88282dc301f",
       "rows": [
        [
         "0",
         "toxicity",
         "57.510928",
         "0.590947"
        ],
        [
         "1",
         "severe_toxicity",
         "57.510928",
         "0.590947"
        ],
        [
         "2",
         "obscene",
         "57.510928",
         "0.590947"
        ],
        [
         "3",
         "threat",
         "57.510928",
         "0.590947"
        ],
        [
         "4",
         "insult",
         "57.510928",
         "0.590947"
        ],
        [
         "5",
         "identity_attack",
         "57.510928",
         "0.590947"
        ],
        [
         "6",
         "sexual_explicit",
         "57.510928",
         "0.590947"
        ],
        [
         "7",
         "AVG",
         "57.510928",
         "0.590947"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>test_infer_seconds</th>\n",
       "      <th>per_sample_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toxicity</td>\n",
       "      <td>57.510928</td>\n",
       "      <td>0.590947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>severe_toxicity</td>\n",
       "      <td>57.510928</td>\n",
       "      <td>0.590947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obscene</td>\n",
       "      <td>57.510928</td>\n",
       "      <td>0.590947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>threat</td>\n",
       "      <td>57.510928</td>\n",
       "      <td>0.590947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insult</td>\n",
       "      <td>57.510928</td>\n",
       "      <td>0.590947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>identity_attack</td>\n",
       "      <td>57.510928</td>\n",
       "      <td>0.590947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sexual_explicit</td>\n",
       "      <td>57.510928</td>\n",
       "      <td>0.590947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AVG</td>\n",
       "      <td>57.510928</td>\n",
       "      <td>0.590947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label  test_infer_seconds  per_sample_ms\n",
       "0         toxicity           57.510928       0.590947\n",
       "1  severe_toxicity           57.510928       0.590947\n",
       "2          obscene           57.510928       0.590947\n",
       "3           threat           57.510928       0.590947\n",
       "4           insult           57.510928       0.590947\n",
       "5  identity_attack           57.510928       0.590947\n",
       "6  sexual_explicit           57.510928       0.590947\n",
       "7              AVG           57.510928       0.590947"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CPU inference benchmarking on test set (RNN multi-label model)\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "original_device = next(model.parameters()).device\n",
    "model_cpu = model.to(\"cpu\").eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        input_ids = batch[\"input_ids\"].to(\"cpu\")\n",
    "        attention_mask = batch[\"attention_mask\"].to(\"cpu\")\n",
    "        _ = model_cpu(input_ids, attention_mask)\n",
    "        break\n",
    "\n",
    "n_samples = 0\n",
    "t0 = time.perf_counter()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(\"cpu\")\n",
    "        attention_mask = batch[\"attention_mask\"].to(\"cpu\")\n",
    "        _ = model_cpu(input_ids, attention_mask)\n",
    "        n_samples += input_ids.size(0)\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "total_seconds = t1 - t0\n",
    "throughput = n_samples / total_seconds if total_seconds > 0 else float(\"inf\")\n",
    "per_sample_ms_all = (total_seconds / n_samples) * 1000.0\n",
    "\n",
    "per_label_timings = [\n",
    "    {\"label\": label, \"test_infer_seconds\": total_seconds, \"per_sample_ms\": per_sample_ms_all}\n",
    "    for label in label_cols\n",
    "]\n",
    "\n",
    "time_metrics_df = pd.DataFrame(per_label_timings)\n",
    "\n",
    "# Append AVG row\n",
    "avg_vals = time_metrics_df.drop(columns=[\"label\"]).mean(numeric_only=True)\n",
    "avg_row = {**{\"label\": \"AVG\"}, **avg_vals.to_dict()}\n",
    "time_metrics_df = pd.concat([time_metrics_df, pd.DataFrame([avg_row])], ignore_index=True)\n",
    "\n",
    "# Round for readability\n",
    "time_metrics_df[\"test_infer_seconds\"] = time_metrics_df[\"test_infer_seconds\"].round(6)\n",
    "time_metrics_df[\"per_sample_ms\"] = time_metrics_df[\"per_sample_ms\"].round(6)\n",
    "\n",
    "print(\"Benchmark (CPU) on test set:\")\n",
    "print(f\" - samples: {n_samples}\")\n",
    "print(f\" - total_inference_seconds_all_labels: {total_seconds:.6f}\")\n",
    "print(f\" - throughput_samples_per_sec_all_labels: {throughput:.2f}\")\n",
    "print(f\" - avg_per_sample_latency_ms_all_labels: {per_sample_ms_all:.6f}\")\n",
    "\n",
    "_ = model_cpu.to(original_device)\n",
    "\n",
    "time_metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pyenv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
